# IO

## BIO

特点：

1. accept是阻塞的，如果不开启线程去处理请求的话，第二个连接就进不来，就会造成进程的阻塞
2. 为了解决这个问题，所以每一个客户端连接都会开启一个线程

存在的问题：

1. 线程过多，就意味着CPU频繁的切换
2. 线程都有自己独立的堆空间，会造成内存的大量浪费

## NIO

### 第一阶段

特点：

1. 内核发展，进程不用阻塞，可以循环遍历去处理每一个客户端的连接

存在的问题：

1. 如果有一万个客户端同时连接，那么就需要进行O(n)次系统调用
2. 如果此时只有2个客户端发来数据了，那么就会造成大量的系统调用

### 第二阶段

select：主动轮训的多路复用，给用户程序返回可读可写的状态

特点：

1. 新增加一个系统调用，内核把可用的文件描述符返回给用户程序

   如果有一万个客户端建立了连接（并不是所有客户端都在发送数据），用户程序（API）把一万个客户端的文件描述符一起发给内核，内核会返给用户程序，哪些可读，哪些可写，然后用户程序再进行下一步的处理。

   每循环一次的时间复杂度O(1)的select，O(n)的 recvform，会比原来性能好很多。

存在的问题：

1. 调用的时候，会传递1万个文件描述，传递的数据很多。如果一个客户端多次发送数据，会产生重复传递（每一次文件描述符的传递都会在用户空间和内核控件进行传递，很浪费性能）
2. 内核主动遍历，需要自己O(n)次遍历，找到可用的文件描述符，增加内核的资源消耗

### 第三阶段

epoll：基于事件的多路复用

用户程序通过多路复用器，获知了哪些可以操作，然后自己去操作（同步）

特点：

1. 内核开辟两块独立的内存空间：1.存储用户程序所有的客户端连接的文件描述符（采用红黑树的数据结构），2.存储可读可写的文件描述符（采用链表的数据结构）。
2. 增加 epoll_create 系统调用，用来创建内存空间。
3. 增加 epoll_ctl（add,del） 系统调用来存储两类文件描述符：1.监听的类的文件描述符，1.可读可写的文件描述符。
4. 增加 epoll_wait 系统调用，用来接收可读可写文件描述的内存空间返回的结果（因为还是有等待，也就是所谓的轮训接收，所以还是同步。zookeeper只要把监听事件注册上了，就不用管了，什么时候触发，由别人决定，这是异步）。
5. 客户端连接的文件描述符当有数据发送和接收的时候，是怎么从1号内存空间转移到2号内存空间的？：通过网卡芯片的中断信号，会触发 callback，然后cpu就会从别的进程切换过来，发现数据到达了，就通过epoll的监听事件把文件描述符转移到2号内存空间，不需要遍历。
6. epoll_wait 可以是阻塞的，也可以是非阻塞的，
   1. redis 是非阻塞的：单进程单线程（需要做的事很多：本身的工作线程，LRU内存回收，RDB数据落地、AOF日志落地），所以不可能让 epoll_wait 处于阻塞状态。
   2. nginx是阻塞的：有守护进程有，工作进程，为了降低轮训带来的性能压力，故使用阻塞方式

## MMAP（一种内存映射文件的方法）

1. java把class load到内存其位置实际是在jvm的堆空间。堆空间存放一些object，data等。

2. 内核获取进程外的东西，非常方便；但是要想获取java堆空间的数据，需要先经过jvm，中间多了一层逻辑转换。

3. java也有堆外空间（使用 unsafe 进行访问），堆外空间只能存储 byte，不需要jvm翻译，比堆内更快

4. 堆外开辟空间，让它和内核共享一块内存，可以使用 mmap来划分，多线程可以同时访问这块区域，同时可以映射到磁盘的文件。使用 mapbuffer（磁盘buffer） 的 put，之后就直接到文件了。

   RandomAccesseFile(filepath).map(4096) => mapbuffer.put

5. kafka：数据从网卡进来，经过内核达到 kafka（recive），增加头部，然后通过mmap直接映射到文件，充分利用磁盘的顺序读写（会形成很多断文件），当缓存中满了，就falsh到磁盘。

6. 内核多了一个 sendfile 的系统调用，可以由用户程序直接调用该系统调用（一般由是由框架封装的API），读取文件的时候，就不需要在经过一个用户空间的拷贝，故称零拷贝。